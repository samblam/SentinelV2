# Edge Inference Performance Benchmark Results

**Date:** 2025-11-17 07:33:42
**Model:** YOLOv5-nano
**Device:** cpu
**Inferences:** 100

---

## Summary

| Metric | Value |
|--------|-------|
| **Mean Inference Time** | 64.10ms ± 20.30ms |
| **Median Inference Time** | 62.45ms |
| **P95 Inference Time** | 70.38ms |
| **P99 Inference Time** | 258.10ms |
| **Min/Max Inference Time** | 40.90ms / 258.10ms |
| **Throughput** | 16.93 inferences/second |
| **Model Size** | 7.50MB |
| **Mean Memory Delta** | 0.46MB |

---

## Detailed Results

### 1. Inference Latency

**Statistics over 100 inferences:**

- **Mean:** 64.10ms
- **Median:** 62.45ms
- **Standard Deviation:** 20.30ms
- **95th Percentile:** 70.38ms
- **99th Percentile:** 258.10ms
- **Range:** 40.90ms - 258.10ms

**Latency Distribution:**
- < 50ms: ✅ Excellent (real-time capable)
- 50-100ms: ✅ Good (acceptable for surveillance)
- 100-200ms: ⚠️  Acceptable (may impact real-time use)
- > 200ms: ❌ Poor (not suitable for real-time)

**Actual Performance:** ✅ 64.10ms (Target: <100ms)

### 2. Throughput

- **Total Inferences:** 170
- **Duration:** 10.04 seconds
- **Throughput:** 16.93 inferences/second

**Throughput Assessment:**
- > 10 fps: ✅ Excellent (suitable for video processing)
- 5-10 fps: ✅ Good (suitable for intermittent capture)
- 1-5 fps: ⚠️  Acceptable (suitable for static monitoring)
- < 1 fps: ❌ Poor (limited use cases)

**Actual Performance:** ✅ 16.93 fps

### 3. Memory Usage

- **Mean Memory Delta:** 0.46MB
- **Peak Memory Delta:** 46.96MB

Memory impact per inference is minimal, suitable for embedded deployment.

### 4. Model Characteristics

- **Model:** YOLOv5-nano
- **Size:** 7.50MB (compressed)
- **Device:** cpu
- **Precision:** FP32 (CPU) or FP16 (GPU if available)

---

## Performance vs. Strategy Targets

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| Inference Time | <100ms | 64.10ms | ✅ PASS |
| Model Size | <10MB | 7.50MB | ✅ PASS |
| Throughput | >5 fps | 16.93 fps | ✅ PASS |

---

## Test Environment

- **Python:** 3.11+
- **PyTorch:** 2.1.0+
- **Ultralytics YOLOv5:** Latest
- **Device:** cpu
- **Image Size:** 640x480 (synthetic test images)

---

## Recommendations

1. **For Production:** Consider GPU acceleration for 5-10x speedup
2. **For Edge Devices:** Current CPU performance is acceptable for surveillance use case
3. **For Optimization:** Consider model quantization (INT8) for faster inference on edge hardware

---

**Generated by:** `edge-inference/benchmarks/benchmark_inference.py`
